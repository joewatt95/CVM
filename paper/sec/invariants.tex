\section{Functional Probabilistic Invariants}\label{sec:invariants}
In this section, we will derive our new technique using \cref{alg:cvm} as an example.
Let us start by briefly reviewing the algorithm---its state is a buffer $\chi$ (initially empty) and a fraction $p > 0$ (initially set to $1$).
The buffer contains a subset of the elements of the stream encountered so far, with maximal size $n$ chosen according to the desired accuracy parameters $\varepsilon$, $\delta$, and the stream size $l$.
The algorithm iterates over the stream elements, adding each one to the buffer with probability $p$ or conversely---if the current stream element is already in the buffer---removing it with probability $(1-p)$.
If the number of elements in the buffer reaches the maximal size $n$, the subsampling operation is executed, which discards each element in $\chi$ independently with probability $\frac{1}{2}$; then, $p$ is adjusted to reflect the fact that the buffer now contains each element with probability $p_\text{new} = \frac{p_\text{old}}{2}$.
If the subsampling operation fails, i.e., if no elements get discarded, then the algorithm fails returing $\bot$.
After processing the stream, the algorithm returns $\frac{|\chi|}{p}$ as a probably-approximately correct value for the number of distinct elements in the stream.

\subsection{A Minor Transformation}
It is convenient to analyze \cref{alg:cvm} without line 11, i.e., we will skip the second check of $|\chi|=n$, determining whether the subsampling step succeeded.
This modified version simplifies our subsequent analysis as we do not have to worry about the possibility of the algorithm failing (returning $\bot$).
This transformation is identically used in the original CVM proof~\cite{chakraborty2023}, where the total variational distance between these two variants of the algorithms is shown to be at most $\frac{\delta}{2}$.
This means probability bounds derived for the modified version, can be transferred to the original algorithm, with a correction term of $\frac{\delta}{2}$.

\subsection{Deriving A Simple Probabilistic Invariant}
Let us consider the random variables $X_s := \indicat(s \in \chi)$ indicating the presence of a stream element $s \in A = \{a_1,\ldots,a_l\}$ in the buffer.\footnote{We use $\indicat$ for the indicator of a predicate, i.e., $\indicat(\mathrm{true}) = 1$ and $\indicat(\mathrm{false}) = 0$.}
Before the algorithm encounters the stream element $s$, $X_s$ will be $0$ unconditionally, because the buffer $\chi$ is always a subset of the stream elements processed so far.
In particular $\chi \subseteq \{a_1,..,a_m\}$ after loop iteration $m$.

In the loop iteration where $s$ occurs the first time, it will be inserted with a probability $p$ in Lines 3--7.
This means, after Line 7, we have:
\begin{equation}
  \label{eq:indicator_eq}
  \expect [p^{-1} X_s] = 1 \textrm{.}
\end{equation}
Interestingly, the equation is preserved for the rest of the algorithm.
For example, let us consider a subsampling step: each $s$ is independently discarded with probability $\frac{1}{2}$ so $\prob(X_s=1)$ is halved, but so will $p$, which preserves the equation.

Let us see how we can verify \cref{eq:indicator_eq} more formally.
For that, we model the state of the algorithm as a pair $(\chi,p)$.
Note that this means $\chi$ and $p$ are random variables on the distribution of the state of the algorithm. 
%For that, let us describe the states of the algorithm using pairs composed of a subset of $A$ representing the buffer $\chi$ and a real number representing $p$.
%Note that, this means $p$ and $\chi$ are random variables, with respect to distributions of the state of the algorithm.
We will refer to parts of each loop iteration in \cref{alg:cvm} as $\mathrm{step}_1$ (resp.~$\mathrm{step}_2$) for lines 3--7 (resp.~lines 8--10).
The final distribution of the algorithm is the distribution resulting from the sequential composition of alternating steps:
\[
  \mathrm{init} \, \isa{\isasymbind}\; \mathrm{step}_1\, a_1 \; \isa{\isasymbind}\; \mathrm{step}_2 \; \isa{\isasymbind}\; \mathrm{step}_1 \, a_2 \; \isa{\isasymbind}\; \cdots \isa{\isasymbind}\; \mathrm{step}_1\, a_l \; \isa{\isasymbind}\; \mathrm{step}_2
\]
where we parameterize $\mathrm{step}_1$ with the stream element that it processes.
The term $\mathrm{init}$ represents the initial state, i.e., $\mathrm{init} = \mathrm{\bf return} (\{\},1)$.
It is easy to show by induction over the sequence of steps, we will have have $0 < p \leq 1$ and $\chi \subseteq A$.

Let us verify that~\cref{eq:indicator_eq} is preserved as an invariant over all steps.
To verify that $\mathrm{step}_1\, a$ preserves \cref{eq:indicator_eq}, i.e., we assume some probability space of states $\Omega$ fulfills \cref{eq:indicator_eq} and we would like to show that it is still true for $\Omega \; \isa{\isasymbind}\; \mathrm{step}_1\, a$.
\[
  \expect_{\Omega \; \isa{\isasymbind}\; \mathrm{step}_1\, a} [ p^{-1} X_s ] =
    \int_\Omega \int_{\Ber(p)} p^{-1} \indicat\left(s \in (\ift{\tau}{\chi \cup \{a\}}{\chi-\{a\}} )\right) \, d \tau d \sigma
\]
Note that, we write $p$ or $\chi$ even though, we should actually write $p(\sigma)$ or $\chi(\sigma)$, i.e., we remember that these depend on $\sigma$.
To see that the right-hand-side is equal to $1$, it is useful to consider the cases where $a=s$ and the converse separately.
In the first case the right-hand-side is equal to $1$, can be seen directly (since $p \in (0;1]$).
In the second case it follows from the induction hypothesis.
(In particular, the term in the inner integral is constant with respect to $\tau$.)

The same is possible for $\mathrm{step}_2$, i.e., let us assume $\Omega$ is a probability space of states fulfilling \cref{eq:indicator_eq}.
Then
\[
  \expect_{\Omega \; \isa{\isasymbind}\; \mathrm{step_2}} \left[\frac{X_s}{p}\right] =
    \int_{\Omega} \left(\ift{|\chi|=n}{\left(\int_{\mathrm{subsample}(\chi)} \frac{\indicat(s \in \tau)}{p/2} \, d \tau\right)}{\frac{\indicat(s \in \chi)}{p}} \right) \, d \sigma \textrm{.}
\]
Note that the true- and false-case both evaluate to the same value: $p^{-1} \indicat(s \in \chi)$.
If $s \notin \chi$ both sides are $0$, because the subsampling operation returns a subset of $\chi$.
If $s \in \chi$ the probability that the element gets subsampled is $1/2$, so we arrive again at $\frac{1/2}{p/2} = p^{-1} \indicat(s \in \chi)$.
Hence: $\expect_{\Omega \; \isa{\isasymbind}\; \mathrm{step_2}} [p^{-1} X_s] = \expect_\Omega [p^{-1} X_s] = 1$.
This completes the invariance proof.

\subsection{Deriving A Functional Probabilistic Invariant}
With \cref{eq:indicator_eq} established, it is straightforward to show that the expectation of the output $p^{-1} |\chi|$ of the modified algorithm (without line 11) is equal to the desired cardinality $|A|$; but we are interested the algorithm's probably-approximately correctness.
A typical approach is to use Chernoff bounds for independent random variables, which provide exponential tail bounds for the deviation of their sums from their mean.
However, these are not directly useful in the CVM algorithm because the key random variables, e.g., $p^{-1} X_s$, are dependent.

An alternative is the Cram\'{e}r--Chernoff method, which is a general method to obtain tail bounds for any random variable.
It can be stated simply as $P(X \geq a) \leq M(t) e^{-ta}$ for all $t > 0$, where $M(t) := \expect [\exp(t X)]$ is the moment generating function of $X$.
%\footnote{The moment generating function is sometimes only defined for some values of $t$ (when the corresponding integral exists), and this is typically an interval including $0$; the inequality is only applicable wherever $M(t)$ is defined.}
%Since the probability space representing the state of the CVM algorithm is finite, $M(t)$ will always be defined in our case.
It is also possible to obtain lower tail bounds $P(X \leq a)$ using Cram\'{e}r--Chernoff method, which just requires estimates for $M(t)$ for $t < 0$, instead of $t > 0$.

In our case, we are interested in estimating the moment generating function of the random variable $p^{-1} |\chi|$ for the CVM algorithm:
\[
  \expect [\exp( t p^{-1} |\chi| )] = \expect \left[ \prod_{s \in A} h(p^{-1} X_s) \right]
\]
for $h(x) = \exp(tx)$.
At this point, it is tempting to see whether the proof for \cref{eq:indicator_eq} can be extended to establish bounds for the above.
We could establish the following result:
\[
  \expect \left[ \prod_{s \in A} h(p^{-1} X_s) \right] \leq h(1)^{|A|}
\]
for every non-negative concave function $h : \mathbb R_{\geq 0} \rightarrow \mathbb R_{\geq 0}$.
We call this a \emph{functional} probabilistic invariant because one can establish it for all valid choices of $h$ with a single induction over steps of the randomized algorithm.

Of course, the exponential function in $M(t)$ is convex, so this is not yet the full story.
However, we can instead try to derive tail bounds for the random variable $\indicat(p \geq q) p^{-1} |\chi|$.
We end up with the condition that $h$ needs to be non-negative and concave only on $[0;q^{-1}]$.
This then allows us to use approximate the exponential function from above with an affine function $h$ on the range $[0;q^{-1}]$, which yields tail bounds for $\prob( |p^{-1} |\chi| - |A|| \geq \varepsilon |A| \wedge p \geq q)$.
To use these bounds, we also have to separately estimate $\prob(p < q)$.
We can use a similar strategy, as in the original proof by Chakraborty et al.~\cite{chakraborty2022}, where they use $q = \frac{n}{4 |A|}$ and separately bound the probability $\prob(p < q)$.

The formalization accompanying this work~\todo{[cite]} contains a detailed informal step-by-step proof using our approach in its appendix.
The algorithm we have verified is actually a slight generalization of the above, where the subsampling probability can be any $f \in [\frac{1}{2};e^{-1/12}]$.
The original CVM algorithm~\cite{chakraborty2022} (\cref{alg:cvm}) is the special case $f=\frac{1}{2}$.
Besides the use of \cref{eq:integral_bind} and the Cram\'er--Chernoff method, the steps are elementary.

The main takeaway here is that it is possible to derive useful and general probabilistic invariants by considering expectations of functions of the state, proved using recursion or induction over the algorithm itself.
As far as we know this method of establishing tail bounds for randomized algorithms is new.


