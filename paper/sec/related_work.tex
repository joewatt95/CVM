\section{Related Work}\label{sec:related_work}
\subsection{Algorithms for the Distinct Elements Problem}
It is important to note that there are several practical solutions for the distinct elements problem.
The first solution was presented by Flajolet~\cite{flajolet1985} in 1985; however, like many other authors~\cite{flajolet2007,heule2013}, his solution makes the assumption that a fixed hash function can be regarded as a fully random function.
Alon et al.~\cite[Section 2.3]{alon1999} presented an easy remedy, which does not require such unmotivated model assumptions.
Their algorithm just relies on keeping track of the maximum of the hash values of the stream elements, where the hash function must be chosen uniformly from a pairwise independent family.

Later, Bar-Yossef et al.~\cite{baryossef2002}, Kane et al.~\cite{kane2010} and B\l{}asiok in 2020~\cite{blasiok2020} improved on the solution by Alon et al.
For example, Bar-Yossef et al.\ present a solution (Algorithm~3 in their work) with a space-complexity of $\bigo(\ln (\delta^{-1}) (\varepsilon^{-2}(\ln(\varepsilon^{-1})+\ln b) + b)))$, which can be implemented in practice.
This is slightly better than the CVM algorithm which requires $\bigo(\varepsilon^{-2} \ln (\delta^{-1}l) b)$. In particular, there is no dependency on the length of the stream $l$.
The more recent and more sophisticated solution by B\l{}asiok is space-optimal, with a space complexity of $\bigo(\varepsilon^{-2} \ln (\delta^{-1}) + b)$.
We~\cite{karayel2023} presented a version of the latter that preserves monotonicity and supports the merge-operation, which enables its use in distributed settings, such as Map-Reduce pipelines~\cite{dean2010}.
It should be noted that these recent algorithms are mostly of theoretical interest, as the constants, as well as the implementation complexity, are rather large.
A comprehensive review of distinct elements algorithms has been compiled by Pettie and Wang~\cite[Table~1]{pettie2021}.
What makes the CVM algorithm unique is its simplicity and the fact that it does not rely on hashing, which may enable more general use-cases than the traditional algorithms.

The aforementioned hash-based algorithms are biased; Flajolet et al.~\cite{flajolet1985} points this out and also provides bounds on the distance between the expected result and the cardinality of the stream.
Most authors do not discuss the matter of bias but it is not hard to show.
One issue, for example, is that the usual method to amplify the accuracy of these algorithms is using the median, which does not preserve expectations.
In the context of query processing, unbiasedness has been discussed~\cite[Section 2.1]{haas1995}, but we could not find any similar discussion for the distinct elements problem in the streaming model.

\subsection{Probabilistic Invariants and Formalization}
As far as we know, probabilistic invariants have not been used to establish exponentially decreasing tail-bounds.
However, it is fairly common to use recursive analysis techniques to establish results about expectations or variance of random variables, such as their run-time~\cite[Section 1.4]{motwani1995}.
This is easy due to the linearity of expectations and---for independent random variables---linearity of variances.
A simple example is the Morris counter~\cite{morris1978} or the expected run-time of the quick-sort algorithm~\cite[Section 2.5]{mitzenmacher2017}.

There is also research on the (automated) analysis of loop invariants, for probabilistic loops, using their characteristic functions~\cite{batz2023, mciver2005}.
This approach works by establishing the limiting distribution of the state of the loop.
De Medeiros et al.~\cite[Section 3.2]{demedeiros2024} also establish methods to derive limiting distributions of probabilistic loops.
Our approach differs from these techniques by avoiding computation of the distribution, which, we think, is infeasible for the CVM algorithm.
Instead, we investigate invariants of classes of functions of the distributions, which are relevant for the analysis.
There is research on automated evaluation of moments for restricted classes of loops which contain only polynomial assignments and no branches~\cite{bartocci2019,kofnov2022}.
However, these methods do not extend to algorithms with non-continuous operations, or control flow that depends on non-deterministic state variables.

Finally, verification of randomized algorithms expressed in functional programming languages has been tackled by various authors using various proof assistants~\cite{audebaud2009,bosshard2024,demedeiros2024, eberl2020,gopinathan20,haslbeck2016,hurd03,Probabilistic_Prime_Tests-AFP,tan2024,tassarotti2021}; the most closely related efforts are our mechanizations of frequency moments algorithms~\cite{karayel2022, karayel2023}.
Moreover, for classical imperative randomized algorithms, there are approaches based on probabilistic Hoare logic~\cite{denhartog2002}.
An interesting related work by Haselwarter et al.~\cite{haselwarter2025} discusses some of the issues we encountered in the transformation-based proof (Section~\ref{sec:transformation_based_proof}), such as (approximate) equivalence between related randomized algorithms.
However, because our work reasons directly over the semantics of randomized algorithms expressed in the Giry monad, we did not deeply explore probabilistic logic-based methods.
