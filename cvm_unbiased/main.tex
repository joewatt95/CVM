\documentclass{article}
\usepackage[left=1.2in, right=1.2in]{geometry}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{algorithmicx}
\usepackage{hyperref}
\newcommand{\prob}{\mathcal P}
\newcommand{\expectation}{\mathrm{E}}
\newcommand{\eps}{\varepsilon}
\newtheorem{theorem}{Theorem}
\theoremstyle{definition}
\newtheorem{lemma}{Lemma}


\begin{document}
\title{Unbiased CVM Algorithm}
\maketitle
\section{Notation}
For a finite set $S$, the probability space of uniformly sampling from the set is denoted by $U(S)$, i.e., for each $s \in S$ we have
$\prob_{U(S)}({s}) = |S|^{-1}$.
For the bernoulli probability space, over the set $\{0,1\}$ we'll write $\mathrm{Ber}(p)$, i.e., $P_{\mathrm{Ber}(p)}(\{1\}) = p$.
$I(P)$ is the indicator function for a predicate $P$, i.e., $I(\mathrm{true}) = 1$ and $I(\mathrm{false}) = 0$.
\section{Algorithm}
Let us fix
\begin{itemize}
  \item $a_1,\ldots,a_l$ for the stream of elements, and
  \item $n$ for the maximal number of elements in the buffer, and
  \item $f$ for the fraction of elements to keep in the buffer, when we subsample.
\end{itemize}
Note that: $nf$ must be an integer $\frac{1}{2} \leq f < 1$.

\begin{algorithm}
\caption{Unbiased CVM algorithm}
\begin{algorithmic}[1]
\State $\chi \gets \emptyset$; $p \gets 1$
\For{$i \gets 1$ to $l$}
  \State $\chi \gets \chi - \{a_i\}$
  \State $\mathrm{coin} \gets \mathrm{Ber}(p)$
  \If{$\mathrm{coin}$}
    \State $\chi \gets \chi \cup \{a_i\}$
  \EndIf
  \If{$|\chi| = n$}
    \State $\chi \gets U(\{ S \subseteq \chi \,|\, |S|=nf \})$
    \State $p \gets p f$
  \EndIf
\EndFor
\State \Return{$p^{-1} |\chi|$}
\end{algorithmic}
\end{algorithm}

We will denote the first five lines of the loop ($4$--$7$) as step 1, the last four lines ($8$--$11$) as step 2, and the distribution of the state of the algorithm after processing $i$ elements of the sequence by $\Omega_i$.
The elements of the probability spaces are pairs composed of a set and a fraction, representing $\chi$ and $p$.
For example: $\Omega_0 = U(\{(\emptyset, 1)\})$ is the initial state, $\Omega_1 = U(\{(\{a_1\}, 1)\})$, etc. $\Omega_l$ denotes the final state.
We introduce $\chi$ and $p$ as random variables defined over such probability spaces $\Omega$, in particular, $\chi$ (resp. $p$) is the projection to the first (resp. second) component.

The state of the algorithm after processing only step 1 of the $i$-th loop iteration is denoted by $\Omega'_i$.
So the sequence of states is represented by the distributions $\Omega_0, \Omega'_1, \Omega_1, \ldots, \Omega'_l, \Omega_l$.
A few easy-to-see observations without proof for any $0 \leq i \leq l$:
\begin{itemize}
\item $p(\omega) \leq 1$ a.s. (almost surely) for $\omega \in \Omega_i$,
\item $\chi(\omega) \subseteq \{a_1,\ldots,a_i\}$ a.s. for $\omega \in \Omega_i$,
\item $|\chi(\omega)| < n$ a.s. for $\omega \in \Omega_i$.
\end{itemize}
Also for the intermediate states, we have:
\begin{itemize}
\item $p(\omega) \leq 1$ a. s. for $\omega \in \Omega'_i$,
\item $\chi(\omega) \subseteq \{a_1,\ldots,a_i\}$ a.s. for $\omega \in \Omega'_i$,
\item $|\chi(\omega)| \leq n$ a.s. for $\omega \in \Omega'_i$.
\end{itemize}
Given a set $T$ with $n$ elements, we'll write $C(T)$ for the $nf$-subsets of $T$, i.e.:
\[
  C(T) = \{ \tau \subseteq T \, | \, |\tau| = nf \} \textrm{.}
\]
\begin{lemma}\label{le:samp_prod}
Let $T$ be a set with $n$ elements, $S \subseteq T$ and $g: \{0,1\} \rightarrow \mathbb R^+$ then
\[
  \int_{U(C(T))} \prod_{s \in S} g(I(s \in \tau)) \leq \prod_{s \in S} \int_{\mathrm{Ber}(f)} g(\tau) d \tau
\]
\end{lemma}
\begin{proof}
We'll verify the cases $g(0) \leq g(1)$ and the converse seperately. For the case $g(0) \leq g(1)$:
We want to use Theorem 2.11 by Joag-Dev and Proschan~\cite{joagdev1983}, which requires us to view $C(T)$ as a permutation distribution.

Let us for that consider $P := U(\{f : T \rightarrow \{0,..,|T|-1\}, f \textrm{bij.}\})$, i.e., we are assigning randomly distinct positions from $0$ to $|T|-1$ to the elements
of $T$. Then $P$ is clearly a permuation distribution and the random variables describing the positions of each element are negatively associated according to Theorem 2.11.

Now we can represent $C(T)$ as the choice of all the elements whose associated position is greater or equal to $(1-f)n$, i.e.:
\begin{equation*}
  \int_{U(C(T))} \prod_{s \in S} g(I(s \in \tau)) = \int_P \prod_{s \in S} g(I(\tau(s) \geq (1-f)n)) \, d\tau := R
\end{equation*}
Now we can use the Property P2~\cite[Page 288]{joagdev1983} since the $\tau(s)$ are negatively associated:
\begin{equation}\label{eq:samp_prod_2}
  R \leq \prod_{s \in S} \int_P g(I(\tau(s) \geq (1-f)n)) \, d\tau
\end{equation}
Note that this works because $x \rightarrow g(I(x \geq (1-f)n))$ is a monotone increasing function.
Moreover the right hand side of Eq.~\ref{eq:samp_prod_2} is easy to be seen to be equal to the right hand side of the lemma we want to show.

For the case $g(0) > g(1)$ we can do a similar trick, except in this case we associate with the choice of $\tau$ the elements with positions $\{0,\ldots,nf-1\}$.
\end{proof}

\begin{lemma}
\label{le:neg_cor}
Let $h : \mathbb R \rightarrow \mathbb R^+$ be a positive concave function, then for all 
$k \in \{0,\ldots,l\}$, $S \subseteq \{a_1,..,a_k\}$:
\begin{align*}
  \expectation_{\Omega_k}\left[ \prod_{s \in S} h(p^{-1} I(s \in \chi)) \right] & \leq h(1)^{|S|} &
  \expectation_{\Omega'_k}\left[ \prod_{s \in S} h(p^{-1} I(s \in \chi)) \right] & \leq h(1)^{|S|}
\end{align*}
\end{lemma}
\begin{proof}
Note because $h$ is concave we can use the reverse Jensen's inequality
\begin{equation}\label{eq:rev_jensen}
  E [ h(X(\omega)) ] \leq h(E X)
\end{equation}
for all integrable random variables and probability spaces. 

We show the result using induction over $k$. Note that we show the statement for arbitrary $S$, e.g., the induction statements are:
\begin{eqnarray*}
P(k) & :\leftrightarrow & \left(\forall S \subseteq \{a_1,..,a_k\}. \; \expectation_{\Omega_k}\left[ \prod_{s \in S} h(p^{-1} I(s \in \chi)) \right] \leq h(1)^{|S|} \right) \\
Q(k) & :\leftrightarrow & \left(\forall S \subseteq \{a_1,..,a_k\}. \; \expectation_{\Omega'_k}\left[ \prod_{s \in S} h(p^{-1} I(s \in \chi)) \right] \leq h(1)^{|S|} \right)
\end{eqnarray*}
and we will show $P(0),Q(1),P(1),Q(2),P(2),\ldots,Q(l),P(l)$ successively.
\paragraph{Induction start $P(0)$:} \phantom{.}\\
We have $S \subseteq \emptyset$, and hence
\[
\expectation_{\Omega_0}\left[ \prod_{s \in S} h(p^{-1} I(s \in \chi)) \right] = \expectation_{\Omega_0}\left[1\right] = 1 \leq h(1)^0 \textrm{.}
\]
\paragraph{Induction step $P(k) \rightarrow Q(k+1)$:} \phantom{.}\\
Let $S \subseteq \{ a_1, \ldots, a_{k+1} \}$ and define $S' := S - \{ a_{k+1} \}$.
Note that $\Omega'_{k+1}$ can be constructed from $\Omega_k$ as a compound distribution, where $a_{k+1}$ is included in the buffer, with the probability $p$, which is itself a random variable over the space $\Omega_k$.

In particular, for example:
\[
\prob_{\Omega'_{k+1}}( P(\chi, p) ) = \int_{\Omega_k} \int_{\textrm{Ber}(p(\omega))} P(\chi(\omega)-\{a_{k+1}\}\cup f(\tau), p(\omega)) \, d \tau \, d \omega
\]
for all predicates $P$ where we define $f(1) = \{a_{k+1}\}$ and $f(0) = \emptyset$.

We distinguish the two cases $a_{k+1} \in S$ and $a_{k+1} \notin S$. If $a_{k+1} \in S$:
\begin{eqnarray*}
  \expectation_{\Omega'_{k+1}}\left[\prod_{s \in S} h(p^{-1} I(s \in \chi)) \right] & = & \int_{\Omega_k} \left(\prod_{s \in S'} h(p^{-1} I(s \in \chi))\right)
  \int_{\mathrm{Ber}(p(\omega))} h(p^{-1} \tau) \, d \tau \, d \omega \\
  & \underset{\textrm{Eq.~\ref{eq:rev_jensen}}}{\leq} & \int_{\Omega_k} \left( \prod_{s \in S'} h(p^{-1} I(s \in \chi)) \right)
  h\left(\int_{\mathrm{Ber}(p(\omega))} p^{-1} \tau \, d \tau\right) \, d \omega \\
  & = & \int_{\Omega_k} \left( \prod_{s \in S'} h(p^{-1} I(s \in \chi)) \right) h(1) \, d \omega \\
  & \underset{\textrm{IH}}{\leq} & h(1)^{|S'|} h(1) = h(1)^{|S|}
\end{eqnarray*}

If $a_{k+1} \notin S$ then $S' = S$ and:
\begin{equation}
  \expectation_{\Omega'_{k+1}}\left[\prod_{s \in S} h(p^{-1} I(s \in \chi)) \right] = \int_{\Omega_k} \prod_{s \in S} h(p^{-1} I(s \in \chi)) \, d \omega \leq_{IH} h(1)^{|S'|} = h(1)^{|S|}
\end{equation}
\paragraph{Induction step $Q(k+1) \rightarrow P(k+1)$:} \phantom{.}\\
Let $S \subseteq \{ a_1, \ldots, a_{k+1} \}$.

Let us again note that $\Omega_{k+1}$ is a compound distribution over $\Omega_k$. In general, for all predicates $P$:
\[
  \prob_{\Omega_{k+1}}( P(\chi, p) )  = \int_{\Omega'_{k+1}} I( |\chi(\omega)|<n ) P(\chi(\omega),p(\omega)) + I( |\chi(\omega)|=n ) \int_{U(\chi(\omega))} P(\tau, f p(\omega)) \, d \tau  \, d \omega \textrm{.}
\]

With this we can can now verify the induction step:
\begin{eqnarray*}
&  & \textstyle\expectation_{\Omega_{k+1}}\left[\prod_{s \in S} h(p^{-1} I(s \in \chi))\right]  \\
& = & \textstyle \int_{\Omega'_{k+1}} I(|\chi| < n)\prod_{s \in S} h(p^{-1} I(s \in \chi)) \, d \omega \\
& + & \textstyle \int_{\Omega'_{k+1}} I(|\chi| = n) \prod_{s \in S \setminus \chi(\omega)} h(0) \int_{U(C(\chi))} \prod_{s \in S \cap \chi} h((pf)^{-1}I(s \in \tau )) d \tau \, d \omega  \\
& \underset{\textrm{Le.~\ref{le:samp_prod}}}{\leq} & \textstyle \int_{\Omega'_{k+1}} I(|\chi| < n)\prod_{s \in S} h(p^{-1} I(s \in \chi)) \, d \omega \\
& + & \textstyle \int_{\Omega'_{k+1}} I(|\chi| = n) \prod_{s \in S \setminus \chi(\omega)} h(0) \prod_{s \in S \cap \chi} \int_{\mathrm{Ber(f)}} h((pf)^{-1}\tau) d \tau \, d \omega  \\
& \underset{\textrm{Eq.~\ref{eq:rev_jensen}}}{\leq} & \textstyle \int_{\Omega'_{k+1}} I(|\chi| < n)\prod_{s \in S} h(p^{-1} I(s \in \chi)) \, d \omega \\
& + & \textstyle \int_{\Omega'_{k+1}} I(|\chi| = n) \prod_{s \in S \setminus \chi(\omega)} h(0) \prod_{s \in S \cap \chi} h\left(\int_{\mathrm{Ber(f)}} (pf)^{-1}\tau d \tau\right) \, d \omega  \\
& = & \textstyle \int_{\Omega'_{k+1}} I(|\chi| < n)\prod_{s \in S} h(p^{-1} I(s \in \chi)) \, d \omega \\
& + & \textstyle \int_{\Omega'_{k+1}} I(|\chi| = n) \prod_{s \in S \setminus \chi(\omega)} h(0) \prod_{s \in S \cap \chi} h(p^{-1}) \, d \omega  \\
& = & \textstyle \int_{\Omega'_{k+1}} I(|\chi| < n)\prod_{s \in S} h(p^{-1} I(s \in \chi)) \, d \omega \\
& + & \textstyle \int_{\Omega'_{k+1}} I(|\chi| = n) \prod_{s \in S} h(p^{-1} I(s \in \chi)) \, d \omega  \\
& = & \textstyle \expectation_{\Omega'_{k+1}}\left[\prod_{s \in S} h(p^{-1} I(s \in \chi)) \right] \underset{\textrm{IH}}{\leq} h(1)^{|S|}
\end{eqnarray*}

\end{proof}

\section{Concentration}
This section establishes that the result of the algorithm is concentrated around the cardinality of $A = \{ a_1, \ldots, a_l \}$. This will be done by Chernoff bounds for the probability that the estimate is above $(1+\eps)|A|$ (resp. below $(1-\eps)|A|$ assuming $p$ is not too small and a tail estimate for $p$ being too small.

It should be noted that concentration is trivial, if $|A| < n$, i.e., if we never need to do sub-sampling.
So we assume $|A| \geq n$.

We define $q := n/(4|A|)$ - notice that $q \leq \frac{1}{4}$. Moreover we'll introduce the notation $\tilde{p} := \max(p,q)$.
Basically $\tilde{p}$ is a clamped version of $p$, and in particular, $\tilde{p}^{-1}$ is bounded from above by $q^{-1}$.

The following is a helper lemma:
\begin{lemma}
\label{le:helper}
For any $\Omega \in \{\Omega_0,\ldots,\Omega_l\} \cup \{\Omega'_1,\ldots,\Omega'_l\}$ and $0 < \eps \leq 1$:
\[
\prob_{\Omega} \left( \tilde{p}^{-1} |\chi| \geq (1+\eps) |A| \right) \leq \exp\left(-\frac{n}{12} \eps^2\right)
\]
\end{lemma}
\begin{proof}
By assumption there exists a $k$ such that $\Omega \in \{\Omega_k, \Omega'_k\}$. Let $A' = A \cap \{a_1,\ldots,a_k\}$.

Moreover, we define
\begin{align*}
  t & := q \ln ( 1 + \frac{\eps}{1-q(1+\eps)}) \\
  h(x) & := 1+qx(e^{t/q}-1)  
\end{align*}

To get a tail estimate, we use the Cram\'{e}r-Chernoff method:
{\allowdisplaybreaks
\begin{eqnarray*}
  \prob_{\Omega} \left( \tilde{p}^{-1} |\chi| \geq (1+\eps) |A| \right) & \leq & \prob_{\Omega} \left( \tilde{p}^{-1} |\chi| \geq (1+\eps) |A'| \right) \\
  & \underset{\textrm{Markov,}t>0}{\leq} & \exp( -t (1+\eps) |A| ) \expectation_\Omega \left[ \exp ( t \tilde{p}^{-1} |\chi| ) \right] \\
 & = & \exp( -t (1+\eps) |A| ) \expectation_\Omega \left[ \prod_{s \in A'} \exp ( t \tilde{p}^{-1} I(s \in \chi) ) \right] \\
 & \leq & \exp( -t (1+\eps) |A| ) \expectation_\Omega \left[ \prod_{s \in A'} h( p^{-1} I(s \in \chi) ) \right] \\
 & \underset{\textrm{Le.~\ref{le:neg_cor}}}{\leq} & \exp( -t (1+\eps) |A| ) h(1)^{|A'|} \\
 & \underset{h(1)\geq 1}{\leq} & \left(\exp( \ln(h(1)) -t (1+\eps))\right) ^ {|A|} 
\end{eqnarray*}}
So we just need to show that (using $|A|=\frac{n}{4q}$):
\[
  \ln(h(1))-t (1+\eps) \leq \frac{-q \eps^2}{3}
\]
The latter can be established by analyzing the function $f(q,\eps) = -\ln (h(1)) +t (1+\eps) - \frac{q\eps^2}{3}$.
For which it is easy to check $f(q,0) = 0$ and the derivative with respect to $\eps$ is positive in the range $0 \leq q \leq 1/4$ and $0 < \eps \leq 1$, i.e.,
$f(q,\eps) \geq 0$.
\end{proof}

Using the previous we can estimate bounds for $p$ becoming too small, as well as, an upper tail bound.
\begin{lemma}\label{le:low_p}
\[
\prob_{\Omega_l}(p < q) \leq l \exp\left( - \frac{n}{12}\right)
\]
\end{lemma}
\begin{proof}
We'll use a similar strategy as in the $\mathrm{Bad}_2$ bound in the original CVM paper.
Let $j$ be maximal, s.t., $q \leq f^j$.

Hence $f^{j+1} < q$ and:
\begin{equation}
\label{eq:f_j}
  f^j \leq 2f f^j < 2q = \frac{n}{2|A|} \textrm{.}
\end{equation}

First, we bound the probability of jumping from $p=f^j$ to $p=f^{j+1}$ at a specific point in the algorithm, e.g., after processing $k$ stream elements.
It can only happen if $|\chi|=n$, $p=f^j$ in $\Omega'_k$.

Then
\begin{eqnarray*}
  \prob_{\Omega'_k} ( |\chi| \geq n \wedge p=f^j) & \leq & \prob( \tilde{p}^{-1} |\chi| \geq f^{-j} n ) \\
    & \underset{\textrm{Eq.~\ref{eq:f_j}}}{\leq} & \prob( \tilde{p}^{-1} |\chi| \geq 2|A| ) \\
    & \underset{\textrm{Le.~\ref{le:helper}}}{\leq} & \exp( - n/12)
\end{eqnarray*}

The probability that this happens ever in the entire process is then at most $l$ times the above which proves the lemma.
\end{proof}

Now we come to the tail bounds. The upper tail bound follows directly from Lemma~\ref{le:helper}:
\begin{lemma}\label{le:upper_tail}
Let $0 < \eps \leq 1$ then:
\[
  L = \prob_{\Omega_l} ( p^{-1} |\chi| \geq (1+\eps)|A| \wedge p \geq q) \leq \exp\left(-\frac{n}{12} \eps^2\right)
\]
\end{lemma}
\begin{proof}
\begin{eqnarray*}
  L & =&  \prob_{\Omega_l} ( \tilde{p}^{-1} |\chi| \geq (1+\eps)|A| \wedge p \geq q) \\
  & \leq & \prob_{\Omega_l} ( \tilde{p}^{-1} |\chi| \geq (1+\eps)|A| ) \\
  & \underset{\textrm{Le.~\ref{le:helper}}}{\leq}  &  \exp\left(-\frac{n}{12} \eps^2\right)
\end{eqnarray*}
\end{proof}

\begin{lemma}\label{le:lower_tail}
Let $0 < \eps < 1$ then:
\[
  L := \prob_{\Omega_l} ( p^{-1} |\chi| \leq (1-\eps)|A| \wedge p \geq q) \leq \exp\left(-\frac{n}{12} \eps^2\right)
\]
\end{lemma}
\begin{proof}
Let us define
\begin{align*}
  t & := - q \ln\left( \frac{(1-\eps)^{-1}-q}{1-q}\right) < 0 \\
  h(x) & := 1+q \min(x,q^{-1}) (e^{t/q}-1)  
\end{align*}

With these definitions we again follow the Cram\'{e}r-Chernoff method:
{\allowdisplaybreaks
\begin{eqnarray*}
  L & = & \prob_{\Omega_l} \left( \tilde{p}^{-1} |\chi| \leq (1-\eps)|A| \right) \\
    & \underset{\textrm{Markov,}t<0}{\leq} & \exp( -t (1-\eps) |A| ) \expectation_\Omega \left[ \exp ( t \tilde{p}^{-1} |\chi| ) \right] \\
    & = & \exp( -t (1-\eps) |A| ) \expectation_\Omega \left[ \prod_{s \in A} \exp ( t \tilde{p}^{-1} I(s \in \chi) ) \right] \\
    & \leq & \exp( -t (1-\eps) |A| ) \expectation_\Omega \left[ \prod_{s \in A} h( p^{-1} I(s \in \chi) ) \right] \\
    & \underset{\textrm{Le.~\ref{le:neg_cor}}}{\leq} & \exp( -t (1-\eps) |A| ) (h(1))^{|A|} \\
    & = & \exp( \ln(h(1)) -t (1-\eps) )^{|A|}
\end{eqnarray*}
}

Substituting $t$ and $h$ and using $|A| = \frac{n}{4q}$, we can see that the lemma is true if
\[
  f(q,\eps) = t (1-\eps) - \ln(1+q(e^{t/q}-1)) - \frac{q}{3} \eps^2
\]
is non-negative for $0 \leq q \leq \frac{1}{4}$ and $0 < \eps < 1$.
This can be verified by checking that $f(q,0) = 0$ and that the derivative with respect to $\eps$ is non-negative.
\end{proof}
We can now establish the concentration result:
\begin{theorem}
Let $0 < \eps < 1$ and $0 < \delta < 1$ and $n \geq \frac{12}{\eps^2} \ln\left(\frac{3l}{\delta}\right)$ then:
\[
  L = \prob_{\Omega_l} \left( | p^{-1} |\chi| - |A| | \geq \eps |A| \right) \leq \delta
\]
\end{theorem}
\begin{proof}
Note that the theorem is trivial if $|A| < n$. If not:
\begin{eqnarray*}
  L & \leq & \prob_{\Omega_l} \left( | p^{-1} |\chi| \leq (1-\eps) |A| \wedge p \geq q \right) +
    \prob_{\Omega_l} \left( | p^{-1} |\chi| \leq (1+\eps) |A| \wedge p \geq q \right) +
    \prob_{\Omega_l} \left( p < q \right) \\
    & \underset{Le.~\ref{le:low_p}-\ref{le:upper_tail}}{\leq} &
    \exp\left( - \frac{n}{12} \eps^2 \right)  + \exp\left( - \frac{n}{12} \eps^2 \right) + l \exp\left( - \frac{n}{12} \right) \\
    & \leq & \frac{\delta}{3} + \frac{\delta}{3} + \frac{\delta}{3}
\end{eqnarray*}
\end{proof}

\section{Unbiasedness}
Let $M$ be large enough such that $p^{-1} \leq M$ a.s. (e.g. we can choose $M = f^{-l}$). Then we can derive from Lemma~\ref{le:neg_cor} using $h(x) = x$ and $h(x) = \max(M-x,0)$ that:
\begin{eqnarray*}
  \expectation_{\Omega_l} [ p^{-1} I(s \in S) ] \leq 1
  \expectation_{\Omega_l} [ M - p^{-1} I(s \in S) ] = \expectation_{\Omega_l} [ M - \max(0,p^{-1} I(s \in S)) ] \leq M-1  
\end{eqnarray*}
which implies $\expectation_{\Omega_l} [ p^{-1} I(s \in S) ] = 1$.
By linearity of expectation we can conclude that
\[
  \expectation_{\Omega_l} [ p^{-1} |\chi| ] = \sum_{s \in A} \expectation_{\Omega_l} [ p^{-1} I(s \in S) ] = |A| \textrm{.}
\]
\bibliographystyle{plainurl}
\bibliography{main} 

\end{document}

